{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progetto di Social Computing\n",
    "\n",
    "a.a. 2022/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attività preliminari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerie e costanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import delle librerie utilizzate\n",
    "import os, tweepy, json\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import random as rn\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cartelle di salvataggio\n",
    "data_folder = \"./data\"\n",
    "out_folder = \"./out\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio in locale\n",
    "def serialize_json(folder, filename, data):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    with open(f\"{folder}/{filename}\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent = 4)\n",
    "        f.close()\n",
    "    print(f\"Data serialized to path: {folder}/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura da locale\n",
    "def read_json(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "        print(f\"Data read from path: {path}\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"No data found at path: {path}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somma dei numeri di tweet prodotti in un intervallo di tempo\n",
    "def sum_tweets_count(tweet_groups):\n",
    "    sum = 0\n",
    "\n",
    "    for tweet_count in tweet_groups:\n",
    "        sum += tweet_count[\"tweet_count\"]\n",
    "    \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_into(user, root_distance, destination):\n",
    "    normalized = {\n",
    "        \"name\" : user[\"name\"],\n",
    "        \"username\" : user[\"username\"],\n",
    "        \"description\" : user[\"description\"],\n",
    "        \"public_metrics\" : user[\"public_metrics\"],\n",
    "        \"protected\" : user[\"protected\"]\n",
    "    }\n",
    "\n",
    "    # Se user non è protetto, si possono aggiungere i dettagli aggiuntivi\n",
    "    if (root_distance < 2 and not user[\"protected\"]):\n",
    "        # Si estraggono le ids dei follower di 'follower'\n",
    "        f_ids = []\n",
    "        for f in user[\"followers\"]:\n",
    "            f_ids.append(f[\"id\"])\n",
    "    \n",
    "        normalized[\"last_week_tweets_count\"] = user[\"last_week_tweets_count\"]\n",
    "        normalized[\"followers\"] = f_ids\n",
    "    \n",
    "    # Non si aggiorna se l'utente è già definito\n",
    "    if user[\"id\"] not in destination:\n",
    "        destination[user[\"id\"]] = normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credenziali Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: ./api_access.json\n"
     ]
    }
   ],
   "source": [
    "# Caricamento credenziali da JSON\n",
    "api_access = read_json(\"./api_access.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recupero dei follower e dei follower dei follower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recupero dei follower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vogliono recuperare, utilizzando la libreria `tweepy`, tutti i follower dell'utente *@KevinRoitero*, corredati delle seguenti informazioni:\n",
    "\n",
    "* attributi di default;\n",
    "* descrizione del profilo;\n",
    "* metriche pubbliche dell'account;\n",
    "* se l'account è protetto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data serialized to path: ./data/user_followers.json\n"
     ]
    }
   ],
   "source": [
    " # Si inizializza il client\n",
    "client = tweepy.Client(bearer_token=api_access[\"bearer_token\"])\n",
    "\n",
    "username = \"KevinRoitero\"\n",
    "all_user_followers = []\n",
    "\n",
    "# Si recuperano e memorizzano le informazioni dell'utente\n",
    "response = client.get_user(username = username, user_fields=[\"description\", \"protected\", \"public_metrics\"])\n",
    "user = dict(response.data)\n",
    "\n",
    "# Si recuperano e memorizzano i follower dell'utente\n",
    "response = client.get_users_followers(user[\"id\"], user_fields=[\"description\", \"protected\", \"public_metrics\"], \n",
    "                                      max_results=150) # max_results = 150 perché i follower dell'utente sono nell'ordine di 130\n",
    "for follower in response.data:\n",
    "    all_user_followers.append(dict(follower))\n",
    "\n",
    "# Si associano i follower trovati all'utente di partenza\n",
    "user[\"followers\"] = all_user_followers\n",
    "\n",
    "# Si serializza su JSON il risultato ottenuto\n",
    "serialize_json(data_folder, \"user_followers.json\", user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggiunta del numero di tweet prodotti nell'ultima settimana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ai follower trovati, si vuole aggiungere il numero di tweet pubblicati nell'ultima settimana. Per avere uniformità, troveremo anche il numero di tweet pubblicati nell'ultima settimana dall'utente *@KevinRoitero*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: ./data/user_followers.json\n",
      "Data serialized to path: ./data/followers_last_week_tweets.json\n"
     ]
    }
   ],
   "source": [
    "# Si sceglie l'utilizzo dello stesso client di partenza, o comunque senza la possibilità di mettersi in attesa, \n",
    "# perché numero_richieste < 300, dove 300 è il numero massimo di richieste per l'endpoint get_recent_tweets_count()\n",
    "client = tweepy.Client(bearer_token=api_access[\"bearer_token\"])\n",
    "\n",
    "# Si caricano i dati dell'utente e quelli dei suoi follower\n",
    "user = read_json(data_folder+\"/user_followers.json\")\n",
    "\n",
    "# Si memorizza il numero di tweet pubblicati dall'utente nell'ultima settimana\n",
    "response = client.get_recent_tweets_count(query=\"from:\"+user[\"username\"], granularity=\"day\")\n",
    "user[\"last_week_tweets_count\"] = sum_tweets_count(response.data)\n",
    "\n",
    "# Si ripete lo stesso per i follower dell'utente\n",
    "for follower in user[\"followers\"]:\n",
    "    if(not follower[\"protected\"]): # non si può accedere ai tweet di un utente 'protected'\n",
    "        response = client.get_recent_tweets_count(query=\"from:\"+follower[\"username\"], granularity=\"day\")\n",
    "        follower[\"last_week_tweets_count\"] = sum_tweets_count(response.data)\n",
    "\n",
    "# Si serializza su JSON il risultato ottenuto\n",
    "serialize_json(data_folder, \"followers_last_week_tweets.json\", user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recupero dei follower dei follower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per ciascun follower di *@KevinRoitero* avente almeno 1 follower e non `protected`, si vogliono scaricare le seguenti informazioni:\n",
    "\n",
    "* attributi di default;\n",
    "* descrizione del profilo;\n",
    "* metriche pubbliche dell'account;\n",
    "* se l'account è protetto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'approccio che è stato seguito è quello di un download *parallelo*, ossia ciascun collaboratore al progetto si è preso in carico di scaricare una porzione di follower dei follower di *@KevinRoitero*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: ./data/followers_last_week_tweets.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 889 seconds.\n",
      "Rate limit exceeded. Sleeping for 893 seconds.\n",
      "Rate limit exceeded. Sleeping for 891 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data serialized to path: ./data/f_of_f_2\n"
     ]
    }
   ],
   "source": [
    "# Si impone al client di attendere nel caso di raggiungimento del limite delle richieste\n",
    "client = tweepy.Client(bearer_token=api_access[\"bearer_token\"], wait_on_rate_limit=True)\n",
    "\n",
    "# Si caricano i dati dell'utente e quelli dei suoi follower\n",
    "user = read_json(data_folder+\"/followers_last_week_tweets.json\")\n",
    "\n",
    "# Parallelizzando il calcolo, si decide di partizionare tra collaboratori il numero di follower\n",
    "all_followers = np.array(user[\"followers\"])\n",
    "\n",
    "f_num = user[\"public_metrics\"][\"followers_count\"]\n",
    "start = f_num*api_access[\"id\"] // 4\n",
    "end = f_num*(api_access[\"id\"]+1) // 4\n",
    "\n",
    "# Si vogliono memorizzare solamente i follower di responsabilità del collaboratore\n",
    "interval_followers = []\n",
    "\n",
    "# Si scaricano i follower dei follower nell'intervallo del collaboratore\n",
    "for i in range(start, end):\n",
    "    # Si considera l'i-esimo follower\n",
    "    follower = all_followers[i]\n",
    "\n",
    "    # Se l'i-esimo follower non è protetto e ha dei follower, li scarico\n",
    "    if (not follower[\"protected\"] and follower[\"public_metrics\"][\"followers_count\"] > 0):\n",
    "        for all_follower_followers in tweepy.Paginator(client.get_users_followers, id = follower[\"id\"], user_fields=[\"description\", \"protected\", \"public_metrics\"], max_results = 1000):\n",
    "            parsed_followers = []\n",
    "            \n",
    "            for ff in all_follower_followers.data:\n",
    "                # L'oggetto User deve essere interpretato\n",
    "                parsed_follower = {\n",
    "                    \"id\" : ff[\"id\"],\n",
    "                    \"public_metrics\" : ff[\"public_metrics\"],\n",
    "                    \"description\" : ff[\"description\"],\n",
    "                    \"name\" : ff[\"name\"],\n",
    "                    \"protected\" : ff[\"protected\"],\n",
    "                    \"username\" : ff[\"username\"]\n",
    "                }\n",
    "                parsed_followers.append(parsed_follower)\n",
    "            \n",
    "            follower[\"followers\"] += parsed_followers\n",
    "    \n",
    "    # Aggiungo il follower (arricchito dei suoi follower) nella lista di follower di competenza del collaboratore\n",
    "    interval_followers.append(follower)\n",
    "\n",
    "# Si salva la porzione di follower scaricata\n",
    "serialize_json(data_folder, \"f_of_f_\"+str(api_access[\"id\"])+\".json\", list(interval_followers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si uniscono ora i file generati dai diversi collaboratori in un unico file JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: ./data/followers_last_week_tweets.json\n",
      "Data read from path: ./data/f_of_f_0.json\n",
      "Data read from path: ./data/f_of_f_1.json\n",
      "Data read from path: ./data/f_of_f_2.json\n",
      "Data read from path: ./data/f_of_f_3.json\n",
      "Data serialized to path: ./data/user_complete.json\n"
     ]
    }
   ],
   "source": [
    "# Si carica il JSON con le informazioni su @KevinRoitero\n",
    "user = read_json(data_folder+\"/followers_last_week_tweets.json\")\n",
    "followers = []\n",
    "\n",
    "for i in range(0, 4):\n",
    "    # Si caricano i follower individuati dal collaboratore i\n",
    "    partial_followers = read_json(data_folder+\"/f_of_f_\"+str(i)+\".json\")\n",
    "    \n",
    "    # Si concatenano all'elenco completo dei follower\n",
    "    followers += partial_followers\n",
    "\n",
    "# Si aggiornano i dati sui follower di @KevinRoitero\n",
    "user[\"followers\"] = followers\n",
    "\n",
    "# Si serializza il risultato ottenuto\n",
    "serialize_json(data_folder, \"user_complete.json\", user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Riformattazione del JSON finale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al fine di essere conformi alle specifiche della consegna, si decide di ristrutturare (ossia modificarne la presentazione, pur mantenendo invariate le informazioni al suo interno) il JSON `user_complete.json` definito in precedenza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il formato che è stato ritenuto come più opportuno, sia per un'efficienza di archiviazione che di computazione (importante per le sezione successive), è il seguente:\n",
    "```json\n",
    "{\n",
    "    ...\n",
    "    id (int) : {\n",
    "        \"name\" : str,\n",
    "        \"username\" : str,\n",
    "        \"description\" : int,\n",
    "        \"public_metrics\" : {\n",
    "            \"followers_count\" : int,\n",
    "            \"following_count\" : int,\n",
    "            \"tweet_count\" : int,\n",
    "            \"listed_count\" : int\n",
    "        },\n",
    "        \"protected\" : bool,\n",
    "        (\"last_week_tweets_count\" :int,)\n",
    "        (\"followers\" : [\n",
    "            ...\n",
    "            f_id (int),\n",
    "            ...\n",
    "        ])\n",
    "    }\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dove `id` rappresenta l'identificativo univoco di un utente, le cui informazioni sono state scaricate nei passi precedenti, ed `f_id` rappresenta l'identificativo di un follower di `id`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "È doveroso far notare che, per come sono stati scaricati gli utenti, solamente coloro che o sono *@KevinRoitero* o sono suoi follower (non `protected`) presentano il campo `last_week_tweets_count` ed il campo `followers` (da cui le parentesi tonde nello schema)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: ./data/user_complete.json\n",
      "Data serialized to path: ./data/users_final.json\n"
     ]
    }
   ],
   "source": [
    "# Si carica il JSON completo, non formattato\n",
    "root_user = read_json(data_folder+\"/user_complete.json\")\n",
    "\n",
    "nodes = {} # JSON finale\n",
    "\n",
    "normalize_into(user = root_user, root_distance=0, destination = nodes)\n",
    "\n",
    "# Si fa la stessa cosa per follower di @KevinRoitero\n",
    "for follower in root_user[\"followers\"]:\n",
    "    normalize_into(user = follower, root_distance = 1, destination = nodes)\n",
    "\n",
    "# ... e per i follower dei follower\n",
    "for follower in root_user[\"followers\"]:\n",
    "    if (not follower[\"protected\"]):\n",
    "        for ff in follower[\"followers\"]:\n",
    "            normalize_into(user = ff, root_distance = 2, destination = nodes)\n",
    "\n",
    "# Si serializza il JSON ben formattato\n",
    "serialize_json(data_folder, \"users_final.json\", nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si consideri che, per come è stato costruito, il file `users_final.json` presenta una struttura ordinata:\n",
    "\n",
    "1. Al primo posto vi sonoi dettagli sul profilo di *@KevinRoitero*;\n",
    "2. dal secondo posto fino al 134-esimo vi sono i follower di *@KevinRoitero*;\n",
    "3. dal 135-esimo posto in poi vi sono i follower dei follower di *@KevinRoitero*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creazione della rete sociale diretta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggiunta dei nodi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come nodi si vogliono avere *@KevinRoitero* ed i suoi follower ed ogni nodo deve rispettare le seguenti caratteristiche:\n",
    "\n",
    "* il suo `id` deve essere uguale all'`id` del profilo utente;\n",
    "* deve avere come attributi:\n",
    "    * lo username;\n",
    "    * la descrizione;\n",
    "    * il numero di follower del profilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: ./data/users_final.json\n"
     ]
    }
   ],
   "source": [
    "# Si crea un grafo diretto vuoto\n",
    "social_graph = nx.DiGraph()\n",
    "\n",
    "# Si considera l'insieme dei profili utente\n",
    "users = read_json(data_folder+\"/users_final.json\")\n",
    "\n",
    "# La struttura del file permette di fare un inserimento \"ordinato\"\n",
    "added = 0\n",
    "for id in users:\n",
    "    user = users[id]\n",
    "    social_graph.add_node(int(id), username = user[\"username\"], \n",
    "                              description = user[\"description\"], \n",
    "                              followers_count = user[\"public_metrics\"][\"followers_count\"])\n",
    "    \n",
    "    added += 1\n",
    "    # Il 134-esimo utente è l'ultimo follower di @KevinRoitero\n",
    "    if(added == 134):\n",
    "        break\n",
    "\n",
    "# N.B.: questo trucchetto dell'inserimento ordinato è possibile solamente grazie al fatto che la funzione read_json() ed il costrutto for,\n",
    "#       rispettivamente, caricano in memoria principale le informazioni in ordine di apparizione ed iterano su di esse rispettando ancora\n",
    "#       il loro ordine di apparizione. Se questi dettagli implementativi dovessero cambiare, sarebbe necessario apportare modifiche anche\n",
    "#       a questa soluzione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggiunta degli archi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al grafo definito precedntemente si vogliono aggiungere archi $(v,w)$ tra due nodi $v$ e $w$ se e solo se il profilo corrispondente a $v$ è follower del profilo corrispondente a $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ereditano le variabili 'social_graph' e 'users' dal chunk precedente\n",
    "for v in social_graph.nodes:\n",
    "    for w in social_graph.nodes:\n",
    "        if ((not v == w) and (not users[str(w)][\"protected\"]) and (v in users[str(w)][\"followers\"])):\n",
    "            social_graph.add_edge(v, w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f523f7c76dd18e7ed336217f32f6f704c23c323644912475b9d3570cf04b060"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
