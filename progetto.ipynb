{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progetto di Social Computing\n",
    "\n",
    "a.a. 2022/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attività preliminari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerie e costanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import delle librerie utilizzate\n",
    "import os, tweepy, json\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import random as rn\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt \n",
    "from pyvis.network import Network \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cartelle di salvataggio\n",
    "data_folder = \"./data\"\n",
    "out_folder = \"./out\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio in locale\n",
    "def serialize_json(folder, filename, data):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    with open(f\"{folder}/{filename}\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent = 4)\n",
    "        f.close()\n",
    "    print(f\"Data serialized to path: {folder}/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura da locale\n",
    "def read_json(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "        print(f\"Data read from path: {path}\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"No data found at path: {path}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somma dei numeri di tweet prodotti in un intervallo di tempo\n",
    "def sum_tweets_count(tweet_groups):\n",
    "    sum = 0\n",
    "\n",
    "    for tweet_count in tweet_groups:\n",
    "        sum += tweet_count[\"tweet_count\"]\n",
    "    \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_into(user, root_distance, destination):\n",
    "    normalized = {\n",
    "        \"name\" : user[\"name\"],\n",
    "        \"username\" : user[\"username\"],\n",
    "        \"description\" : user[\"description\"],\n",
    "        \"public_metrics\" : user[\"public_metrics\"],\n",
    "        \"protected\" : user[\"protected\"]\n",
    "    }\n",
    "\n",
    "    # Se user non è protetto, si possono aggiungere i dettagli aggiuntivi\n",
    "    if (root_distance < 2 and not user[\"protected\"]):\n",
    "        # Si estraggono le ids dei follower di 'follower'\n",
    "        f_ids = []\n",
    "        for f in user[\"followers\"]:\n",
    "            f_ids.append(f[\"id\"])\n",
    "    \n",
    "        normalized[\"last_week_tweets_count\"] = user[\"last_week_tweets_count\"]\n",
    "        normalized[\"followers\"] = f_ids\n",
    "    \n",
    "    # Non si aggiorna se l'utente è già definito\n",
    "    if user[\"id\"] not in destination:\n",
    "        destination[user[\"id\"]] = normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credenziali Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: ./api_access.json\n"
     ]
    }
   ],
   "source": [
    "# Caricamento credenziali da JSON\n",
    "api_access = read_json(\"./api_access.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recupero dei follower e dei follower dei follower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recupero dei follower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vogliono recuperare, utilizzando la libreria `tweepy`, tutti i follower dell'utente *@KevinRoitero*, corredati delle seguenti informazioni:\n",
    "\n",
    "* attributi di default;\n",
    "* descrizione del profilo;\n",
    "* metriche pubbliche dell'account;\n",
    "* se l'account è protetto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data serialized to path: ./data/user_followers.json\n"
     ]
    }
   ],
   "source": [
    " # Si inizializza il client\n",
    "client = tweepy.Client(bearer_token=api_access[\"bearer_token\"])\n",
    "\n",
    "username = \"KevinRoitero\"\n",
    "all_user_followers = []\n",
    "\n",
    "# Si recuperano e memorizzano le informazioni dell'utente\n",
    "response = client.get_user(username = username, user_fields=[\"description\", \"protected\", \"public_metrics\"])\n",
    "user = dict(response.data)\n",
    "\n",
    "# Si recuperano e memorizzano i follower dell'utente\n",
    "response = client.get_users_followers(user[\"id\"], user_fields=[\"description\", \"protected\", \"public_metrics\"], \n",
    "                                      max_results=150) # max_results = 150 perché i follower dell'utente sono nell'ordine di 130\n",
    "for follower in response.data:\n",
    "    all_user_followers.append(dict(follower))\n",
    "\n",
    "# Si associano i follower trovati all'utente di partenza\n",
    "user[\"followers\"] = all_user_followers\n",
    "\n",
    "# Si serializza su JSON il risultato ottenuto\n",
    "serialize_json(data_folder, \"user_followers.json\", user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggiunta del numero di tweet prodotti nell'ultima settimana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ai follower trovati, si vuole aggiungere il numero di tweet pubblicati nell'ultima settimana. Per avere uniformità, troveremo anche il numero di tweet pubblicati nell'ultima settimana dall'utente *@KevinRoitero*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: ./data/user_followers.json\n",
      "Data serialized to path: ./data/followers_last_week_tweets.json\n"
     ]
    }
   ],
   "source": [
    "# Si sceglie l'utilizzo dello stesso client di partenza, o comunque senza la possibilità di mettersi in attesa, \n",
    "# perché numero_richieste < 300, dove 300 è il numero massimo di richieste per l'endpoint get_recent_tweets_count()\n",
    "client = tweepy.Client(bearer_token=api_access[\"bearer_token\"])\n",
    "\n",
    "# Si caricano i dati dell'utente e quelli dei suoi follower\n",
    "user = read_json(data_folder+\"/user_followers.json\")\n",
    "\n",
    "# Si memorizza il numero di tweet pubblicati dall'utente nell'ultima settimana\n",
    "response = client.get_recent_tweets_count(query=\"from:\"+user[\"username\"], granularity=\"day\")\n",
    "user[\"last_week_tweets_count\"] = sum_tweets_count(response.data)\n",
    "\n",
    "# Si ripete lo stesso per i follower dell'utente\n",
    "for follower in user[\"followers\"]:\n",
    "    if(not follower[\"protected\"]): # non si può accedere ai tweet di un utente 'protected'\n",
    "        response = client.get_recent_tweets_count(query=\"from:\"+follower[\"username\"], granularity=\"day\")\n",
    "        follower[\"last_week_tweets_count\"] = sum_tweets_count(response.data)\n",
    "\n",
    "# Si serializza su JSON il risultato ottenuto\n",
    "serialize_json(data_folder, \"followers_last_week_tweets.json\", user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recupero dei follower dei follower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per ciascun follower di *@KevinRoitero* avente almeno 1 follower e non `protected`, si vogliono scaricare le seguenti informazioni:\n",
    "\n",
    "* attributi di default;\n",
    "* descrizione del profilo;\n",
    "* metriche pubbliche dell'account;\n",
    "* se l'account è protetto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'approccio che è stato seguito è quello di un download *parallelo*, ossia ciascun collaboratore al progetto si è preso in carico di scaricare una porzione di follower dei follower di *@KevinRoitero*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: ./data/followers_last_week_tweets.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 889 seconds.\n",
      "Rate limit exceeded. Sleeping for 893 seconds.\n",
      "Rate limit exceeded. Sleeping for 891 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data serialized to path: ./data/f_of_f_2\n"
     ]
    }
   ],
   "source": [
    "# Si impone al client di attendere nel caso di raggiungimento del limite delle richieste\n",
    "client = tweepy.Client(bearer_token=api_access[\"bearer_token\"], wait_on_rate_limit=True)\n",
    "\n",
    "# Si caricano i dati dell'utente e quelli dei suoi follower\n",
    "user = read_json(data_folder+\"/followers_last_week_tweets.json\")\n",
    "\n",
    "# Parallelizzando il calcolo, si decide di partizionare tra collaboratori il numero di follower\n",
    "all_followers = np.array(user[\"followers\"])\n",
    "\n",
    "f_num = user[\"public_metrics\"][\"followers_count\"]\n",
    "start = f_num*api_access[\"id\"] // 4\n",
    "end = f_num*(api_access[\"id\"]+1) // 4\n",
    "\n",
    "# Si vogliono memorizzare solamente i follower di responsabilità del collaboratore\n",
    "interval_followers = []\n",
    "\n",
    "# Si scaricano i follower dei follower nell'intervallo del collaboratore\n",
    "for i in range(start, end):\n",
    "    # Si considera l'i-esimo follower\n",
    "    follower = all_followers[i]\n",
    "\n",
    "    # Se l'i-esimo follower non è protetto e ha dei follower, li scarico\n",
    "    if (not follower[\"protected\"] and follower[\"public_metrics\"][\"followers_count\"] > 0):\n",
    "        for all_follower_followers in tweepy.Paginator(client.get_users_followers, id = follower[\"id\"], user_fields=[\"description\", \"protected\", \"public_metrics\"], max_results = 1000):\n",
    "            parsed_followers = []\n",
    "            \n",
    "            for ff in all_follower_followers.data:\n",
    "                # L'oggetto User deve essere interpretato\n",
    "                parsed_follower = {\n",
    "                    \"id\" : ff[\"id\"],\n",
    "                    \"public_metrics\" : ff[\"public_metrics\"],\n",
    "                    \"description\" : ff[\"description\"],\n",
    "                    \"name\" : ff[\"name\"],\n",
    "                    \"protected\" : ff[\"protected\"],\n",
    "                    \"username\" : ff[\"username\"]\n",
    "                }\n",
    "                parsed_followers.append(parsed_follower)\n",
    "            \n",
    "            follower[\"followers\"] += parsed_followers\n",
    "    \n",
    "    # Aggiungo il follower (arricchito dei suoi follower) nella lista di follower di competenza del collaboratore\n",
    "    interval_followers.append(follower)\n",
    "\n",
    "# Si salva la porzione di follower scaricata\n",
    "serialize_json(data_folder, \"f_of_f_\"+str(api_access[\"id\"])+\".json\", list(interval_followers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si uniscono ora i file generati dai diversi collaboratori in un unico file JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: ./data/followers_last_week_tweets.json\n",
      "Data read from path: ./data/f_of_f_0.json\n",
      "Data read from path: ./data/f_of_f_1.json\n",
      "Data read from path: ./data/f_of_f_2.json\n",
      "Data read from path: ./data/f_of_f_3.json\n",
      "Data serialized to path: ./data/user_complete.json\n"
     ]
    }
   ],
   "source": [
    "# Si carica il JSON con le informazioni su @KevinRoitero\n",
    "user = read_json(data_folder+\"/followers_last_week_tweets.json\")\n",
    "followers = []\n",
    "\n",
    "for i in range(0, 4):\n",
    "    # Si caricano i follower individuati dal collaboratore i\n",
    "    partial_followers = read_json(data_folder+\"/f_of_f_\"+str(i)+\".json\")\n",
    "    \n",
    "    # Si concatenano all'elenco completo dei follower\n",
    "    followers += partial_followers\n",
    "\n",
    "# Si aggiornano i dati sui follower di @KevinRoitero\n",
    "user[\"followers\"] = followers\n",
    "\n",
    "# Si serializza il risultato ottenuto\n",
    "serialize_json(data_folder, \"user_complete.json\", user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Riformattazione del JSON finale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al fine di essere conformi alle specifiche della consegna, si decide di ristrutturare (ossia modificarne la presentazione, pur mantenendo invariate le informazioni al suo interno) il JSON `user_complete.json` definito in precedenza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il formato che è stato ritenuto come più opportuno, sia per un'efficienza di archiviazione che di computazione (importante per le sezione successive), è il seguente:\n",
    "```json\n",
    "{\n",
    "    ...\n",
    "    id (int) : {\n",
    "        \"name\" : str,\n",
    "        \"username\" : str,\n",
    "        \"description\" : int,\n",
    "        \"public_metrics\" : {\n",
    "            \"followers_count\" : int,\n",
    "            \"following_count\" : int,\n",
    "            \"tweet_count\" : int,\n",
    "            \"listed_count\" : int\n",
    "        },\n",
    "        \"protected\" : bool,\n",
    "        (\"last_week_tweets_count\" :int,)\n",
    "        (\"followers\" : [\n",
    "            ...\n",
    "            f_id (int),\n",
    "            ...\n",
    "        ])\n",
    "    }\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dove `id` rappresenta l'identificativo univoco di un utente, le cui informazioni sono state scaricate nei passi precedenti, ed `f_id` rappresenta l'identificativo di un follower di `id`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "È doveroso far notare che, per come sono stati scaricati gli utenti, solamente coloro che o sono *@KevinRoitero* o sono suoi follower (non `protected`) presentano il campo `last_week_tweets_count` ed il campo `followers` (da cui le parentesi tonde nello schema)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: ./data/user_complete.json\n",
      "Data serialized to path: ./data/users_final.json\n"
     ]
    }
   ],
   "source": [
    "# Si carica il JSON completo, non formattato\n",
    "root_user = read_json(data_folder+\"/user_complete.json\")\n",
    "\n",
    "nodes = {} # JSON finale\n",
    "\n",
    "normalize_into(user = root_user, root_distance=0, destination = nodes)\n",
    "\n",
    "# Si fa la stessa cosa per follower di @KevinRoitero\n",
    "for follower in root_user[\"followers\"]:\n",
    "    normalize_into(user = follower, root_distance = 1, destination = nodes)\n",
    "\n",
    "# ... e per i follower dei follower\n",
    "for follower in root_user[\"followers\"]:\n",
    "    if (not follower[\"protected\"]):\n",
    "        for ff in follower[\"followers\"]:\n",
    "            normalize_into(user = ff, root_distance = 2, destination = nodes)\n",
    "\n",
    "# Si serializza il JSON ben formattato\n",
    "serialize_json(data_folder, \"users_final.json\", nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si consideri che, per come è stato costruito, il file `users_final.json` presenta una struttura ordinata:\n",
    "\n",
    "1. Al primo posto vi sonoi dettagli sul profilo di *@KevinRoitero*;\n",
    "2. dal secondo posto fino al 134-esimo vi sono i follower di *@KevinRoitero*;\n",
    "3. dal 135-esimo posto in poi vi sono i follower dei follower di *@KevinRoitero*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creazione della rete sociale diretta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggiunta dei nodi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come nodi si vogliono avere *@KevinRoitero* ed i suoi follower ed ogni nodo deve rispettare le seguenti caratteristiche:\n",
    "\n",
    "* il suo `id` deve essere uguale all'`id` del profilo utente;\n",
    "* deve avere come attributi:\n",
    "    * lo username;\n",
    "    * la descrizione;\n",
    "    * il numero di follower del profilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m social_graph \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mDiGraph()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Si considera l'insieme dei profili utente\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m users \u001b[38;5;241m=\u001b[39m \u001b[43mread_json\u001b[49m(data_folder\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/users_final.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# La struttura del file permette di fare un inserimento \"ordinato\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m added \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'read_json' is not defined"
     ]
    }
   ],
   "source": [
    "# Si crea un grafo diretto vuoto\n",
    "social_graph = nx.DiGraph()\n",
    "\n",
    "# Si considera l'insieme dei profili utente\n",
    "users = read_json(data_folder+\"/users_final.json\")\n",
    "\n",
    "# La struttura del file permette di fare un inserimento \"ordinato\"\n",
    "added = 0\n",
    "for id in users:\n",
    "    user = users[id]\n",
    "    social_graph.add_node(int(id), username = user[\"username\"], \n",
    "                              description = user[\"description\"], \n",
    "                              followers_count = user[\"public_metrics\"][\"followers_count\"])\n",
    "    \n",
    "    added += 1\n",
    "    # Il 134-esimo utente è l'ultimo follower di @KevinRoitero\n",
    "    if(added == 134):\n",
    "        break\n",
    "\n",
    "# N.B.: questo trucchetto dell'inserimento ordinato è possibile solamente grazie al fatto che la funzione read_json() ed il costrutto for,\n",
    "#       rispettivamente, caricano in memoria principale le informazioni in ordine di apparizione ed iterano su di esse rispettando ancora\n",
    "#       il loro ordine di apparizione. Se questi dettagli implementativi dovessero cambiare, sarebbe necessario apportare modifiche anche\n",
    "#       a questa soluzione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggiunta degli archi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al grafo definito precedentemente si vogliono aggiungere archi $(v,w)$ tra due nodi $v$ e $w$ se e solo se il profilo corrispondente a $v$ è follower del profilo corrispondente a $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ereditano le variabili 'social_graph' e 'users' dal chunk precedente\n",
    "for v in social_graph.nodes:\n",
    "    for w in social_graph.nodes:\n",
    "        if ((not v == w) and (not users[str(w)][\"protected\"]) and (v in users[str(w)][\"followers\"])):\n",
    "            social_graph.add_edge(v, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generazione grafo con Preferential Attachment \n",
    "Generazione del secondo grafo secondo gli step: \n",
    "  - conversione del grafo in versione indiretta \n",
    "  - uso della funzione barabasi_albert_graph per ottenere un grafo con il preferential attachment con:\n",
    "    - grafo con il doppio dei nodi \n",
    "    - ogni nodo con due archi uscenti "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computazione del secondo grafo \n",
    "number_of_nodes = social_graph.number_of_nodes()\n",
    "undirected_graph = social_graph.to_undirected()\n",
    "# definizione del secondo grafo \n",
    "graph_preferential = nx.barabasi_albert_graph(number_of_nodes*2, 2, initial_graph = undirected_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizzazione statica NetworkX con layout Fruchterman Reigold**\n",
    "\n",
    "\n",
    "Per il grafo diretto la dimensione dei nodi dipende dal grado in ingresso del nodo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(G, pos, measures, measure_name):\n",
    "    nodes = nx.draw_networkx_nodes(G, pos, node_size=150, cmap=plt.cm.plasma, \n",
    "                                   node_color=list(measures.values()),\n",
    "                                   nodelist=measures.keys())\n",
    "    # labels = nx.draw_networkx_labels(G, pos)\n",
    "    edges = nx.draw_networkx_edges(G, pos)\n",
    "    plt.title(measure_name)\n",
    "    plt.colorbar(nodes)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "in_degree_weight = []\n",
    "for node in social_graph.nodes():\n",
    "    in_degree_weight.append(social_graph.in_degree[nodes])\n",
    "\n",
    "\n",
    "rcParams['figure.figsize'] = 10, 10\n",
    "nx.draw_networkx(\n",
    "    social_graph, \n",
    "    pos=nx.spring_layout(social_graph),\n",
    "    node_color='#A0CBE2',\n",
    "    width=2,\n",
    "    edge_cmap=plt.cm.Blues,\n",
    "    with_labels=True,\n",
    "    node_size = in_degree_weight\n",
    ")\n",
    "plt.savefig(\"social_graph.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per il grafo indiretto la dimensione dipende dal grado del nodo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_degree_weight = []\n",
    "for node in graph_preferential.nodes():\n",
    "    in_degree_weight.append(graph_preferential.in_degree[nodes])\n",
    "\n",
    "\n",
    "rcParams['figure.figsize'] = 10, 10\n",
    "nx.draw_networkx(\n",
    "    graph_preferential, \n",
    "    pos=nx.spring_layout(graph_preferential),\n",
    "    node_color='#A0CBE2',\n",
    "    width=2,\n",
    "    edge_cmap=plt.cm.Blues,\n",
    "    with_labels=True,\n",
    "    node_size = in_degree_weight\n",
    ")\n",
    "plt.savefig(\"social_graph.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificazione della più grande componente fortemente connessa\n",
    "Per ciascuno dei due grafi, identificare la più grande componente fortemente\n",
    "connessa SCC e produrre una visualizzazione statica del grafo con una colorazione\n",
    "rossa dei nodi appartenenti alla SCC, nera per gli altri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifico la SCC più grande\n",
    "largest = max(nx.strongly_connected_components(social_graph), key=len)\n",
    "\n",
    "#specifico una color map, per mappare il colore di ogni nodo come specificato nel testo \n",
    "color_map=[]\n",
    "for node in social_graph:\n",
    "    if node in largest:\n",
    "        #se il nodo fa parte della SCC più grande lo coloro di rosso\n",
    "        color_map.append('red')\n",
    "    else:\n",
    "        #senno di nero\n",
    "        color_map.append('black')\n",
    "\n",
    "#specifico la dimensione della figura, per avere un grafo ben visibile e grande\n",
    "plt.figure(figsize=(18,18))\n",
    "#funzione per disegnare dove utilizzo la color map creata prima\n",
    "nx.draw_networkx(social_graph, node_color = color_map, with_labels = False)\n",
    "plt.savefig(out_folder+\"/graphSCC.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcolo misure di centralità\n",
    "Calcolare le seguenti misure di centralità sui due grafi: Betweenness centrality, Closeness centrality, Degree centrality, In-degree centrality, Out-degree centrality, Page Rank, HITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness_centrality = nx.betweenness_centrality(social_graph)\n",
    "closeness_centrality = nx.closeness_centrality(social_graph)\n",
    "degree_centrality = nx.degree_centrality(social_graph)\n",
    "in_degree_centrality = nx.in_degree_centrality(social_graph)\n",
    "out_degree_centrality = nx.out_degree_centrality(social_graph)\n",
    "pagerank = nx.pagerank(social_graph)\n",
    "hits = nx.hits(social_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficenti per la stima della small-wordness \n",
    "Coefficente omega = (Lr/L) - (C/Cl) \n",
    " - C = coefficente di clustering \n",
    " - L = shortest path medio \n",
    " - Lr = shortest path medio randomico \n",
    "\n",
    "Coefficente sigma = (C/Cr) / (L/Lr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i valori sono calcolati solamente per il grafo indiretto \n",
    "sigma_value = nx.sigma(graph_preferential)\n",
    "omega_value = nx.omega(graph_preferential)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f523f7c76dd18e7ed336217f32f6f704c23c323644912475b9d3570cf04b060"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
