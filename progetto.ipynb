{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progetto di Social Computing\n",
    "\n",
    "a.a. 2022/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attività preliminari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerie e costanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import delle librerie utilizzate\n",
    "import os, tweepy, json\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import random as rn\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cartelle di salvataggio\n",
    "data_folder = \"./data\"\n",
    "out_folder = \"./out\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio in locale\n",
    "def serialize_json(folder, filename, data):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    with open(f\"{folder}/{filename}\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent = 4)\n",
    "        f.close()\n",
    "    print(f\"Data serialized to path: {folder}/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura da locale\n",
    "def read_json(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "        print(f\"Data read from path: {path}\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"No data found at path: {path}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somma dei numeri di tweet prodotti in un intervallo di tempo\n",
    "def sum_tweets_count(tweet_groups):\n",
    "    sum = 0\n",
    "\n",
    "    for tweet_count in tweet_groups:\n",
    "        sum += tweet_count[\"tweet_count\"]\n",
    "    \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credenziali Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: ./api_access.json\n"
     ]
    }
   ],
   "source": [
    "# Caricamento credenziali da JSON\n",
    "api_access = read_json(\"./api_access.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recupero dei follower e dei follower dei follower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recupero dei follower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vogliono recuperare, utilizzando la libreria `tweepy`, tutti i follower dell'utente *@KevinRoitero*, corredati delle seguenti informazioni:\n",
    "\n",
    "* attributi di default;\n",
    "* descrizione del profilo;\n",
    "* metriche pubbliche dell'account;\n",
    "* se l'account è protetto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data serialized to path: ./data/user_followers.json\n"
     ]
    }
   ],
   "source": [
    " # Si inizializza il client\n",
    "client = tweepy.Client(bearer_token=api_access[\"bearer_token\"])\n",
    "\n",
    "username = \"KevinRoitero\"\n",
    "all_user_followers = []\n",
    "\n",
    "# Si recuperano e memorizzano le informazioni dell'utente\n",
    "response = client.get_user(username = username, user_fields=[\"description\", \"protected\", \"public_metrics\"])\n",
    "user = dict(response.data)\n",
    "\n",
    "# Si recuperano e memorizzano i follower dell'utente\n",
    "response = client.get_users_followers(user[\"id\"], user_fields=[\"description\", \"protected\", \"public_metrics\"], \n",
    "                                      max_results=150) # max_results = 150 perché i follower dell'utente sono nell'ordine di 130\n",
    "for follower in response.data:\n",
    "    all_user_followers.append(dict(follower))\n",
    "\n",
    "# Si associano i follower trovati all'utente di partenza\n",
    "user[\"followers\"] = all_user_followers\n",
    "\n",
    "# Si serializza su JSON il risultato ottenuto\n",
    "serialize_json(data_folder, \"user_followers.json\", user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggiunta del numero di tweet prodotti nell'ultima settimana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ai follower trovati, si vuole aggiungere il numero di tweet pubblicati nell'ultima settimana. Per avere uniformità, troveremo anche il numero di tweet pubblicati nell'ultima settimana dall'utente *@KevinRoitero*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: ./data/user_followers.json\n",
      "Data serialized to path: ./data/followers_last_week_tweets.json\n"
     ]
    }
   ],
   "source": [
    "# Si sceglie l'utilizzo dello stesso client di partenza, o comunque senza la possibilità di mettersi in attesa, \n",
    "# perché numero_richieste < 300, dove 300 è il numero massimo di richieste per l'endpoint get_recent_tweets_count()\n",
    "client = tweepy.Client(bearer_token=api_access[\"bearer_token\"])\n",
    "\n",
    "# Si caricano i dati dell'utente e quelli dei suoi follower\n",
    "user = read_json(data_folder+\"/user_followers.json\")\n",
    "\n",
    "# Si memorizza il numero di tweet pubblicati dall'utente nell'ultima settimana\n",
    "response = client.get_recent_tweets_count(query=\"from:\"+user[\"username\"], granularity=\"day\")\n",
    "user[\"last_week_tweets_count\"] = sum_tweets_count(response.data)\n",
    "\n",
    "# Si ripete lo stesso per i follower dell'utente\n",
    "for follower in user[\"followers\"]:\n",
    "    if(not follower[\"protected\"]): # non si può accedere ai tweet di un utente 'protected'\n",
    "        response = client.get_recent_tweets_count(query=\"from:\"+follower[\"username\"], granularity=\"day\")\n",
    "        follower[\"last_week_tweets_count\"] = sum_tweets_count(response.data)\n",
    "\n",
    "# Si serializza su JSON il risultato ottenuto\n",
    "serialize_json(data_folder, \"followers_last_week_tweets.json\", user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recupero dei follower dei follower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per ciascun follower di *@KevinRoitero* avente almeno 1 follower e non `protected`, si vogliono scaricare le seguenti informazioni:\n",
    "\n",
    "* attributi di default;\n",
    "* descrizione del profilo;\n",
    "* metriche pubbliche dell'account;\n",
    "* se l'account è protetto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'approccio che è stato seguito è quello di un download *parallelo*, ossia ciascun collaboratore al progetto si è preso in carico di scaricare una porzione di follower dei follower di *@KevinRoitero*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: ./data/followers_last_week_tweets.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 891 seconds.\n",
      "Rate limit exceeded. Sleeping for 890 seconds.\n",
      "Rate limit exceeded. Sleeping for 888 seconds.\n",
      "Rate limit exceeded. Sleeping for 887 seconds.\n",
      "Rate limit exceeded. Sleeping for 888 seconds.\n",
      "Rate limit exceeded. Sleeping for 886 seconds.\n",
      "Rate limit exceeded. Sleeping for 887 seconds.\n",
      "Rate limit exceeded. Sleeping for 887 seconds.\n",
      "Rate limit exceeded. Sleeping for 888 seconds.\n",
      "Rate limit exceeded. Sleeping for 887 seconds.\n",
      "Rate limit exceeded. Sleeping for 888 seconds.\n",
      "Rate limit exceeded. Sleeping for 886 seconds.\n",
      "Rate limit exceeded. Sleeping for 886 seconds.\n",
      "Rate limit exceeded. Sleeping for 887 seconds.\n",
      "Rate limit exceeded. Sleeping for 887 seconds.\n",
      "Rate limit exceeded. Sleeping for 887 seconds.\n",
      "Rate limit exceeded. Sleeping for 888 seconds.\n",
      "Rate limit exceeded. Sleeping for 888 seconds.\n",
      "Rate limit exceeded. Sleeping for 888 seconds.\n",
      "Rate limit exceeded. Sleeping for 887 seconds.\n",
      "Rate limit exceeded. Sleeping for 886 seconds.\n",
      "Rate limit exceeded. Sleeping for 888 seconds.\n",
      "Rate limit exceeded. Sleeping for 887 seconds.\n",
      "Rate limit exceeded. Sleeping for 887 seconds.\n",
      "Rate limit exceeded. Sleeping for 887 seconds.\n",
      "Rate limit exceeded. Sleeping for 887 seconds.\n",
      "Rate limit exceeded. Sleeping for 887 seconds.\n",
      "Rate limit exceeded. Sleeping for 890 seconds.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type ndarray is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17588\\3782078111.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# Si salva la porzione di follower scaricata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mserialize_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"f_of_f_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_access\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollowers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17588\\17563066.py\u001b[0m in \u001b[0;36mserialize_json\u001b[1;34m(folder, filename, data)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{folder}/{filename}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Data serialized to path: {folder}/{filename}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\stefa\\anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;31m# a debuggability cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\stefa\\anaconda3\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    436\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Circular reference detected\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m             \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\stefa\\anaconda3\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m--> 179\u001b[1;33m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[0;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type ndarray is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# Si impone al client di attendere nel caso di raggiungimento del limite delle richieste\n",
    "client = tweepy.Client(bearer_token=api_access[\"bearer_token\"], wait_on_rate_limit=True)\n",
    "\n",
    "# Si caricano i dati dell'utente e quelli dei suoi follower\n",
    "user = read_json(data_folder+\"/followers_last_week_tweets.json\")\n",
    "\n",
    "# Parallelizzando il calcolo, si decide di partizionare tra collaboratori il numero di follower\n",
    "followers = np.array(user[\"followers\"])\n",
    "\n",
    "f_num = user[\"public_metrics\"][\"followers_count\"]\n",
    "start = f_num*api_access[\"id\"] // 4\n",
    "end = f_num*(api_access[\"id\"]+1) // 4 \n",
    "\n",
    "# Si scaricano i follower dei follower nell'intervallo del collaboratore\n",
    "for i in range(start, end):\n",
    "    follower = followers[i]\n",
    "    \n",
    "    follower[\"followers\"] = []\n",
    "\n",
    "    if (not follower[\"protected\"] and follower[\"public_metrics\"][\"followers_count\"] > 0):\n",
    "        for all_follower_followers in tweepy.Paginator(client.get_users_followers, id = follower[\"id\"], user_fields=[\"description\", \"protected\", \"public_metrics\"], max_results = 1000):\n",
    "            parsed_followers = []\n",
    "            \n",
    "            for ff in all_follower_followers.data:\n",
    "                # L'oggetto User deve essere interpretato\n",
    "                parsed_follower = {\n",
    "                    \"id\" : ff[\"id\"],\n",
    "                    \"public_metrics\" : ff[\"public_metrics\"],\n",
    "                    \"description\" : ff[\"description\"],\n",
    "                    \"name\" : ff[\"name\"],\n",
    "                    \"protected\" : ff[\"protected\"],\n",
    "                    \"username\" : ff[\"username\"]\n",
    "                }\n",
    "                parsed_followers.append(parsed_follower)\n",
    "            \n",
    "            follower[\"followers\"] += parsed_followers\n",
    "\n",
    "# Si salva la porzione di follower scaricata\n",
    "serialize_json(data_folder, \"f_of_f_\"+str(api_access[\"id\"]), list(followers))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f523f7c76dd18e7ed336217f32f6f704c23c323644912475b9d3570cf04b060"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
