{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progetto di Social Computing\n",
    "\n",
    "a.a. 2022-2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attività preliminari"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerie e costanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento delle librerie\n",
    "import os, json, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cartelle di salvataggio\n",
    "data_folder = \"./data\"\n",
    "out_folder = \"./out\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio in locale\n",
    "def serialize_json(folder, filename, data):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    with open(f\"{folder}/{filename}\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent = 4)\n",
    "        f.close()\n",
    "    print(f\"Data serialized to path: {folder}/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura da locale\n",
    "def read_json(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "        print(f\"Data read from path: {path}\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"No data found at path: {path}\")\n",
    "        return {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caricamento del dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si carica il dataset fornito, frammento della combinazione dei dataset [FEVER](https://fever.ai/dataset/fever.html) e [e-FEVER](https://doi.org/10.3929/ethz-b-000453826)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>statement</th>\n",
       "      <th>explanation_human</th>\n",
       "      <th>explanation_model</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51526</td>\n",
       "      <td>Hush (2016 film) was produced by Jason Blum.</td>\n",
       "      <td>Hush (2016 film) was produced by Trevor Macy a...</td>\n",
       "      <td>The evidence says that the film was produced b...</td>\n",
       "      <td>REFUTES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77465</td>\n",
       "      <td>Winter's Tale was released in 1987.</td>\n",
       "      <td>Winter's Tale was released in 2014.</td>\n",
       "      <td>The claim is that Winter's Tale was released i...</td>\n",
       "      <td>REFUTES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166632</td>\n",
       "      <td>Anne Rice was born in the United States of Ame...</td>\n",
       "      <td>Anne Rice was born in New Orleans, Louisiana, ...</td>\n",
       "      <td>The claim is that Anne Rice was born in the Un...</td>\n",
       "      <td>SUPPORTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                          statement  \\\n",
       "0   51526       Hush (2016 film) was produced by Jason Blum.   \n",
       "1   77465                Winter's Tale was released in 1987.   \n",
       "2  166632  Anne Rice was born in the United States of Ame...   \n",
       "\n",
       "                                   explanation_human  \\\n",
       "0  Hush (2016 film) was produced by Trevor Macy a...   \n",
       "1                Winter's Tale was released in 2014.   \n",
       "2  Anne Rice was born in New Orleans, Louisiana, ...   \n",
       "\n",
       "                                   explanation_model     label  \n",
       "0  The evidence says that the film was produced b...   REFUTES  \n",
       "1  The claim is that Winter's Tale was released i...   REFUTES  \n",
       "2  The claim is that Anne Rice was born in the Un...  SUPPORTS  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Si carica e si mostra il dataset fornito\n",
    "df = pd.read_csv(\"./group_9.csv\")\n",
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creazione degli HITs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con il dataset fornito, vogliamo creare creare dodici HITs aventi le seguenti caratteristiche:\n",
    "\n",
    "1. contiene 3 elementi;\n",
    "2. ogni elemento è dotato di 4 attributi:\n",
    "   1. `id`: identificatore dello statement;\n",
    "   2. `statement`: testo dello statement;\n",
    "   3. `explanation`: testo della spiegazione;\n",
    "   4. `label`: etichetta della spiegazione.\n",
    "3. per due elementi su tre vale che `explanation` = `explanation_model`;\n",
    "4. per un elemento su tre vale che `explanation` = `explanation_human`;\n",
    "5. la posizione dei tre elementi deve essere casuale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per l'interpretazione delle righe del dataset\n",
    "def parse_row(row, isGold = False):\n",
    "    parsed = {\n",
    "        \"id\" : row.id,\n",
    "        \"statement\" : row.statement,\n",
    "        \"explanation\" : row.explanation_model,\n",
    "        \"label\" : row.label,\n",
    "        \"isGold\" : isGold\n",
    "    }\n",
    "\n",
    "    # Se è una \"domanda d'oro\", la spiegazione deve essere quella fornita da un essere umano\n",
    "    if isGold:\n",
    "        parsed[\"explanation\"] = row.explanation_human\n",
    "    \n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data serialized to path: ./data/all_HITs.json\n"
     ]
    }
   ],
   "source": [
    "# Creiamo tutte le possibili permutazioni dei 3 elementi secondo quanto stabilito dalla consegna\n",
    "all_HITs = []\n",
    "\n",
    "# Iteriamo sulle spiegazioni fornite dai modelli di machine learning\n",
    "for model_exp in df.itertuples():\n",
    "    model_HITs = []\n",
    "\n",
    "    # Iteriamo sugli altri \"statements\"\n",
    "    for other_stat in df.itertuples():\n",
    "        if other_stat.id != model_exp.id:\n",
    "            # Inseriamo la versione con la \"domanda d'oro\" per la spiegazione del modello (model_exp)\n",
    "            other_model_HIT = [parse_row(model_exp), parse_row(model_exp, True), parse_row(other_stat)]\n",
    "            # Inseriamo la versione con la \"domanda d'oro\" per questo statement (other_stat)\n",
    "            other_gold_HIT = [parse_row(model_exp), parse_row(other_stat, True), parse_row(other_stat)]\n",
    "\n",
    "            # Riordiniamo pseudo-casualmente gli elementi\n",
    "            random.shuffle(other_model_HIT)\n",
    "            random.shuffle(other_gold_HIT)\n",
    "            # Aggiungiamo le HIT create a quelle relative a questa spiegazione (model_exp)\n",
    "            model_HITs.append(other_model_HIT)\n",
    "            model_HITs.append(other_gold_HIT)\n",
    "    \n",
    "    # Si concatena il tutto a tutti gli HITs possibili\n",
    "    all_HITs += model_HITs\n",
    "\n",
    "# Riposizioniamo gli elementi della lista in maniera pseudo-causale\n",
    "random.shuffle(all_HITs)\n",
    "\n",
    "# Salviamo la lista degli HIT creata\n",
    "serialize_json(data_folder, \"all_HITs.json\", all_HITs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adattamento degli HITs per Crowd_Frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ristrutturiamo gli HITs generati precedentemente in modo da renderli leggibili al software [Crowd_Frame](https://github.com/Miccighel/Crowd_Frame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_string(n_chars):\n",
    "    random_string = \"\"\n",
    "    for i in range(n_chars):\n",
    "        # Generiamo un carattere minuscolo\n",
    "        random_integer = random.randint(97, 97 + 26 - 1)\n",
    "        flip_bit = random.randint(0, 1)\n",
    "        # Lo rendiamo casualmente maiuscolo\n",
    "        random_integer = random_integer - 32 if flip_bit == 1 else random_integer\n",
    "        # Concateniamo alla stringa casuale\n",
    "        random_string += chr(random_integer)\n",
    "    return random_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: ./data/all_HITs.json\n",
      "Data serialized to path: ./out/hits.json\n"
     ]
    }
   ],
   "source": [
    "# Carichiamo gli HITs generati\n",
    "raw_HITs = read_json(data_folder+\"/all_HITs.json\")\n",
    "\n",
    "HITs = []\n",
    "id = 0\n",
    "documents_number = 3\n",
    "\n",
    "for raw_HIT in raw_HITs:\n",
    "    # Creiamo l'HIT definitiva\n",
    "    HIT = {\n",
    "        \"unit_id\" : \"unit_\"+str(id),\n",
    "        \"token_input\" : generate_random_string(10),\n",
    "        \"token_output\" : generate_random_string(10),\n",
    "        \"documents_number\" : documents_number\n",
    "    }\n",
    "    # Aggiungiamo i documenti\n",
    "    documents = []\n",
    "    for element in raw_HIT:\n",
    "        # Discriminiamo le domande d'oro\n",
    "        pre = \"G_\" if element[\"isGold\"] else \"N_\"\n",
    "        # Creiamo il documento con i suoi attributi e lo aggiungiamo\n",
    "        document = {\n",
    "            \"id\" : pre+str(element[\"id\"]),\n",
    "            \"statement\" : element[\"statement\"],\n",
    "            \"label\" : element[\"label\"],\n",
    "            \"explanation\" : element[\"explanation\"]\n",
    "        }\n",
    "        documents.append(document)\n",
    "    # Associamo i documenti riformattati all'HIT\n",
    "    HIT[\"documents\"] = documents\n",
    "    # Aggiungiamo l'HIT all'insieme delle HIT\n",
    "    HITs.append(HIT)\n",
    "    # Incremetiamo il valore dell'id\n",
    "    id += 1\n",
    "\n",
    "# Si esporta il tutto oome file JSON\n",
    "serialize_json(out_folder, \"hits.json\", HITs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisi dei risultati"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent agreement per le variabili categoriali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair_pa(df, dimension, w1, w2):\n",
    "    dim_name = \"doc_\"+dimension+\"_value\"\n",
    "    w1_rows = df.loc[df[\"worker_id\"] == w1]\n",
    "    w2_rows = df.loc[df[\"worker_id\"] == w2]\n",
    "    w1_docs = list(w1_rows[\"doc_id\"])\n",
    "    w2_docs = list(w2_rows[\"doc_id\"])\n",
    "\n",
    "    docs = [doc for doc in w1_docs if doc in w2_docs]\n",
    "\n",
    "    if (len(docs) == 0):\n",
    "        return -1\n",
    "    else:\n",
    "        total = len(docs)\n",
    "        n_agree = 0\n",
    "        w1_rows = w1_rows[w1_rows[\"doc_id\"].isin(docs)]\n",
    "        w2_rows = w2_rows[w2_rows[\"doc_id\"].isin(docs)]\n",
    "\n",
    "        for doc in docs:\n",
    "            v1 = list(w1_rows[w1_rows[\"doc_id\"] == doc][dim_name])[0]\n",
    "            v2 = list(w2_rows[w2_rows[\"doc_id\"] == doc][dim_name])[0]\n",
    "            if (v1 == v2):\n",
    "                n_agree += 1\n",
    "        \n",
    "        return n_agree / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dimension_pa(df, dimension):\n",
    "    workers = list(df[\"worker_id\"].drop_duplicates())\n",
    "    percent_agreement = []\n",
    "    \n",
    "    for worker_1 in workers:\n",
    "        pair_agreement = {\n",
    "            \"worker_x\" : worker_1,\n",
    "        }\n",
    "        for worker_2 in workers:\n",
    "            pair_agreement[worker_2] = get_pair_pa(df, dimension, worker_1, worker_2)\n",
    "        percent_agreement.append(pair_agreement)\n",
    "    \n",
    "    pa = pd.DataFrame.from_dict(percent_agreement, orient=\"columns\")\n",
    "    pa = pa.set_index(\"worker_x\")\n",
    "    return pa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truthfulness-1 percent agreement\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1TEEFJDPVEK0L</th>\n",
       "      <th>A2N1GA8PJDDA6P</th>\n",
       "      <th>A2Q51AC4E6I5ZB</th>\n",
       "      <th>A2Z4OTGC834F3Y</th>\n",
       "      <th>A348JKD82WQ6Z</th>\n",
       "      <th>A3OAQZM6Q3YJQ1</th>\n",
       "      <th>A3T2NTPGB3KNDS</th>\n",
       "      <th>A3W16X5D0VGU0E</th>\n",
       "      <th>AYKZJHEV29ZHL</th>\n",
       "      <th>AYUF9OHXQK2YT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_x</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1TEEFJDPVEK0L</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2N1GA8PJDDA6P</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2Q51AC4E6I5ZB</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2Z4OTGC834F3Y</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A348JKD82WQ6Z</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3OAQZM6Q3YJQ1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3T2NTPGB3KNDS</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3W16X5D0VGU0E</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AYKZJHEV29ZHL</th>\n",
       "      <td>50.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AYUF9OHXQK2YT</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A1TEEFJDPVEK0L  A2N1GA8PJDDA6P  A2Q51AC4E6I5ZB  \\\n",
       "worker_x                                                         \n",
       "A1TEEFJDPVEK0L           100.0        0.000000             0.0   \n",
       "A2N1GA8PJDDA6P             0.0      100.000000             0.0   \n",
       "A2Q51AC4E6I5ZB             0.0        0.000000           100.0   \n",
       "A2Z4OTGC834F3Y             0.0        0.000000           100.0   \n",
       "A348JKD82WQ6Z              0.0        0.000000             0.0   \n",
       "A3OAQZM6Q3YJQ1             0.0      100.000000             0.0   \n",
       "A3T2NTPGB3KNDS            -1.0       -1.000000           100.0   \n",
       "A3W16X5D0VGU0E             0.0        0.000000             0.0   \n",
       "AYKZJHEV29ZHL             50.0       33.333333             0.0   \n",
       "AYUF9OHXQK2YT              0.0        0.000000             0.0   \n",
       "\n",
       "                A2Z4OTGC834F3Y  A348JKD82WQ6Z  A3OAQZM6Q3YJQ1  A3T2NTPGB3KNDS  \\\n",
       "worker_x                                                                        \n",
       "A1TEEFJDPVEK0L             0.0       0.000000        0.000000            -1.0   \n",
       "A2N1GA8PJDDA6P             0.0       0.000000      100.000000            -1.0   \n",
       "A2Q51AC4E6I5ZB           100.0       0.000000        0.000000           100.0   \n",
       "A2Z4OTGC834F3Y           100.0     100.000000      100.000000            -1.0   \n",
       "A348JKD82WQ6Z            100.0     100.000000       66.666667            -1.0   \n",
       "A3OAQZM6Q3YJQ1           100.0      66.666667      100.000000            -1.0   \n",
       "A3T2NTPGB3KNDS            -1.0      -1.000000       -1.000000           100.0   \n",
       "A3W16X5D0VGU0E           100.0      66.666667       33.333333            -1.0   \n",
       "AYKZJHEV29ZHL              0.0       0.000000      100.000000            -1.0   \n",
       "AYUF9OHXQK2YT             50.0     100.000000      100.000000            -1.0   \n",
       "\n",
       "                A3W16X5D0VGU0E  AYKZJHEV29ZHL  AYUF9OHXQK2YT  \n",
       "worker_x                                                      \n",
       "A1TEEFJDPVEK0L        0.000000      50.000000            0.0  \n",
       "A2N1GA8PJDDA6P        0.000000      33.333333            0.0  \n",
       "A2Q51AC4E6I5ZB        0.000000       0.000000            0.0  \n",
       "A2Z4OTGC834F3Y      100.000000       0.000000           50.0  \n",
       "A348JKD82WQ6Z        66.666667       0.000000          100.0  \n",
       "A3OAQZM6Q3YJQ1       33.333333     100.000000          100.0  \n",
       "A3T2NTPGB3KNDS       -1.000000      -1.000000           -1.0  \n",
       "A3W16X5D0VGU0E      100.000000       0.000000           50.0  \n",
       "AYKZJHEV29ZHL         0.000000     100.000000            0.0  \n",
       "AYUF9OHXQK2YT        50.000000       0.000000          100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truthfulness-2 percent agreement\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1TEEFJDPVEK0L</th>\n",
       "      <th>A2N1GA8PJDDA6P</th>\n",
       "      <th>A2Q51AC4E6I5ZB</th>\n",
       "      <th>A2Z4OTGC834F3Y</th>\n",
       "      <th>A348JKD82WQ6Z</th>\n",
       "      <th>A3OAQZM6Q3YJQ1</th>\n",
       "      <th>A3T2NTPGB3KNDS</th>\n",
       "      <th>A3W16X5D0VGU0E</th>\n",
       "      <th>AYKZJHEV29ZHL</th>\n",
       "      <th>AYUF9OHXQK2YT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_x</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1TEEFJDPVEK0L</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2N1GA8PJDDA6P</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2Q51AC4E6I5ZB</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2Z4OTGC834F3Y</th>\n",
       "      <td>66.666667</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A348JKD82WQ6Z</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3OAQZM6Q3YJQ1</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3T2NTPGB3KNDS</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3W16X5D0VGU0E</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AYKZJHEV29ZHL</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AYUF9OHXQK2YT</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A1TEEFJDPVEK0L  A2N1GA8PJDDA6P  A2Q51AC4E6I5ZB  \\\n",
       "worker_x                                                         \n",
       "A1TEEFJDPVEK0L      100.000000        0.000000           100.0   \n",
       "A2N1GA8PJDDA6P        0.000000      100.000000             0.0   \n",
       "A2Q51AC4E6I5ZB      100.000000        0.000000           100.0   \n",
       "A2Z4OTGC834F3Y       66.666667       50.000000             0.0   \n",
       "A348JKD82WQ6Z       100.000000        0.000000             0.0   \n",
       "A3OAQZM6Q3YJQ1      100.000000        0.000000             0.0   \n",
       "A3T2NTPGB3KNDS       -1.000000       -1.000000             0.0   \n",
       "A3W16X5D0VGU0E      100.000000        0.000000             0.0   \n",
       "AYKZJHEV29ZHL         0.000000       66.666667             0.0   \n",
       "AYUF9OHXQK2YT       100.000000        0.000000           100.0   \n",
       "\n",
       "                A2Z4OTGC834F3Y  A348JKD82WQ6Z  A3OAQZM6Q3YJQ1  A3T2NTPGB3KNDS  \\\n",
       "worker_x                                                                        \n",
       "A1TEEFJDPVEK0L       66.666667     100.000000      100.000000            -1.0   \n",
       "A2N1GA8PJDDA6P       50.000000       0.000000        0.000000            -1.0   \n",
       "A2Q51AC4E6I5ZB        0.000000       0.000000        0.000000             0.0   \n",
       "A2Z4OTGC834F3Y      100.000000     100.000000      100.000000            -1.0   \n",
       "A348JKD82WQ6Z       100.000000     100.000000       66.666667            -1.0   \n",
       "A3OAQZM6Q3YJQ1      100.000000      66.666667      100.000000            -1.0   \n",
       "A3T2NTPGB3KNDS       -1.000000      -1.000000       -1.000000           100.0   \n",
       "A3W16X5D0VGU0E      100.000000      66.666667       33.333333            -1.0   \n",
       "AYKZJHEV29ZHL        50.000000       0.000000        0.000000            -1.0   \n",
       "AYUF9OHXQK2YT        50.000000     100.000000      100.000000            -1.0   \n",
       "\n",
       "                A3W16X5D0VGU0E  AYKZJHEV29ZHL  AYUF9OHXQK2YT  \n",
       "worker_x                                                      \n",
       "A1TEEFJDPVEK0L      100.000000       0.000000          100.0  \n",
       "A2N1GA8PJDDA6P        0.000000      66.666667            0.0  \n",
       "A2Q51AC4E6I5ZB        0.000000       0.000000          100.0  \n",
       "A2Z4OTGC834F3Y      100.000000      50.000000           50.0  \n",
       "A348JKD82WQ6Z        66.666667       0.000000          100.0  \n",
       "A3OAQZM6Q3YJQ1       33.333333       0.000000          100.0  \n",
       "A3T2NTPGB3KNDS       -1.000000      -1.000000           -1.0  \n",
       "A3W16X5D0VGU0E      100.000000       0.000000           50.0  \n",
       "AYKZJHEV29ZHL         0.000000     100.000000            0.0  \n",
       "AYUF9OHXQK2YT        50.000000       0.000000          100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answers = pd.read_csv(\"./result/secondo_progetto_social_computing/Dataframe/workers_answers.csv\",\n",
    "                        usecols=[\"worker_id\", \"unit_id\", \"doc_id\", \"doc_truthfulness-1_value\", \"doc_explanation-quality_value\", \"doc_truthfulness-2_value\", \"doc_time_elapsed\"])\n",
    "answers = answers.loc[answers.reset_index().groupby([\"worker_id\", \"doc_id\"])[\"doc_time_elapsed\"].idxmax()]\n",
    "\n",
    "for dimension in [\"truthfulness-1\", \"truthfulness-2\"]:\n",
    "    pa = get_dimension_pa(answers, dimension)\n",
    "    pa.to_csv(out_folder+\"/\"+dimension+\"_pa.csv\")\n",
    "    print(dimension+\" percent agreement\")\n",
    "    display(pa)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentuale di testo annotato"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6bbff785f7dca992236909a4969e32f59102c4fceccb1043997c81bace8c71c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
